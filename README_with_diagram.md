
# ğŸ  House Prices Prediction â€” Regression Project

A complete end-to-end machine learning workflow applied to the **Kaggle House Prices** dataset.  
This project includes EDA, preprocessing, baseline models, stacking, and a final Kaggle-ready submission.

---

## ğŸ“Š Exploratory Data Analysis (EDA)

### Scatter Plot Example
![Scatter Plot](assets/graphs/scatterPlots/GarageArea.png)

### Box Plot Example
![Box Plot](assets/graphs/boxPlots/GarageCond.png)

### Histogram Example
![SalePrice Histogram](assets/graphs/histPlot/SalePriceHist2.png)

### Correlation Heatmap
![Correlation Heatmap](assets/graphs/heatMap/heatmap.png)

---

## ğŸ§¼ Data Cleaning & Preprocessing

- Removal of extreme outliers
- Cleaning of missing values
- Feature dropping based on correlation and redundancy
- Feature engineering (`TotalSF`, `TotalBath`, `HouseAge`, etc.)

Preprocessing is handled using **ColumnTransformer** with:
- StandardScaler for numerical features
- OneHotEncoder for categorical features

---

## ğŸ¤– Models Implemented

- **Ridge Regression**
- **RandomForestRegressor**
- **XGBoostRegressor**
- **LightGBM**
- **CatBoost**

All models wrapped in:
```
TransformedTargetRegressor(func=log1p, inverse_func=expm1)
```

---

## ğŸ† Stacked Ensemble

A stacking regressor combining:

- Ridge  
- RandomForest  
- XGBoost
- LightGBM
- CatBoost

with **Ridge** as the meta-learner.

---

## ğŸ§ª Model Evaluation

Evaluation performed using **5-fold cross-validation** with **RMSE**.

---

## ğŸ“¤ Final Submission

Final Kaggle-ready predictions saved as:

```
submission.csv
```

---

## ğŸ“ Project Structure

```
ğŸ“¦ House-Price-Prediction/
â”œâ”€â”€ house_price_prediction.ipynb
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â”œâ”€â”€ submission.csv
â”œâ”€â”€ GarageArea.png
â”œâ”€â”€ GarageCond.png
â”œâ”€â”€ heatmap.png
â”œâ”€â”€ SalePriceHist2.png
â””â”€â”€ README.md
```

---

## ğŸ“š What I Learned

- How to conduct structured EDA  
- Detect and handle outliers  
- Build preprocessing pipelines  
- Compare regression models  
- Use stacking to improve predictions  
- Build a complete ML pipeline from data to submission  

---

## ğŸš€ Future Improvements

- Hyperparameter tuning (Optuna)
- Advanced stacking/blending
- SHAP interpretability
- Feature engineering expansion

---

## ğŸ—ºï¸ Project Setup Diagram

```mermaid
flowchart TD

    A[ğŸ“¥ Raw Data<br>(train.csv & test.csv)] --> B[ğŸ” EDA<br>Scatter Â· Hist Â· Box Â· Heatmap]
    B --> C[ğŸ§¼ Data Cleaning<br>Outliers Â· Missing Â· Drops]
    C --> D[ğŸ§© Feature Engineering<br>TotalSF Â· TotalBath Â· HouseAge]
    D --> E[âš™ï¸ Preprocessing Pipeline<br>Numeric + Categorical]
    E --> F[ğŸ¤– Baseline Models<br>Ridge Â· RF Â· XGBoost]
    F --> G[ğŸ§± Stacking Ensemble<br>Meta: Ridge]
    G --> H[ğŸ“¤ Predictions<br>submission.csv]

    style A fill:#dae8fc,stroke:#6c8ebf
    style B fill:#ffe6cc,stroke:#d79b00
    style C fill:#f8cecc,stroke:#b85450
    style D fill:#e1d5e7,stroke:#9673a6
    style E fill:#d5e8d4,stroke:#82b366
    style F fill:#fff2cc,stroke:#d6b656
    style G fill:#f5f5f5,stroke:#999999
    style H fill:#cfe2f3,stroke:#6fa8dc
```

---

## â–¶ï¸ How to Run This Project

### **1. Install dependencies**
```bash
pip install -r requirements.txt
```

### **2. Open the notebook**
```bash
jupyter notebook house_price_prediction.ipynb
```

### **3. Run all cells**
Make sure `train.csv` and `test.csv` are in the same directory as the notebook.

### **4. Generate final predictions**
The notebook will automatically create:
```
submission.csv
```
You can upload this file to Kaggle for scoring.

---

## ğŸš€ Future Improvements

- Hyperparameter tuning with Optuna  
- GitHub Actions for notebook execution & HTML export  
- SHAP interpretability

---

## ğŸ“¬ Contact
If you'd like to discuss the project, collaborate, or see more of my work:

**Author:** Mateus Vieira Vasconcelos  
**GitHub:** https://github.com/ludoteca12
